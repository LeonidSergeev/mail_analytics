{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import numpy as np\n",
    "pd.set_option('display.max_row', 1000)\n",
    "# --------------------------\n",
    "\n",
    "# -------------------------\n",
    "# infile = '16_new.csv'\n",
    "infile = '/Users/l.sergeev/Downloads/old_experiment_4_raw.csv'\n",
    "\n",
    "columns_2 = [\n",
    "    'subscription_type'\n",
    "#    ,'progress'\n",
    "    ,'from'\n",
    "#    ,'track_duration'\n",
    "#    ,'duration'\n",
    "    ,'progress'\n",
    "    ,'track_id'\n",
    "]\n",
    "\n",
    "chunk_size = 10_000\n",
    "\n",
    "autoclean = True\n",
    "verbose = False\n",
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(infile,nrows=10)\n",
    "date_file = data['dtEvent'][0]\n",
    "event_file = data['eventName'][0]\n",
    "version = \"5.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = '/Users/l.sergeev/Downloads/result_android' + '_' + event_file + '_' + date_file + '.csv'\n",
    "outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------------------------------------------------------------\n",
    "try:\n",
    "    f = open(infile)\n",
    "except IOError:\n",
    "    print('Unable to open file ' + \"'\" + infile + \"'\")\n",
    "    exit(0)\n",
    "\n",
    "wc_l = subprocess.run([\"wc\", \"-l\", infile], stdout=subprocess.PIPE, universal_newlines=True)\n",
    "total_rows = int(wc_l.stdout.split()[0])  # определяем количество строк во входном csv\n",
    "total_rows -= 1  # без заголовка\n",
    "\n",
    "print('total_rows:', '{0:,}'.format(total_rows).replace(',', '_'))\n",
    "\n",
    "n_procs = mp.cpu_count()  # определяем число доступных ядер\n",
    "print('n_procs:', n_procs, end='\\n\\n')\n",
    "# ------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# ---------------------------------------------\n",
    "def str_to_list(s):\n",
    "    return s[1:-1].replace('\\'', '').split(',')\n",
    "# ---------------------------------------------\n",
    "\n",
    "\n",
    "# -------------------------------------------------------\n",
    "def remove_file(filename, no_warn=False):\n",
    "    if os.path.exists(filename):\n",
    "        os.remove(filename)\n",
    "    elif not no_warn:\n",
    "        print('File \\'' + filename + '\\' does not exist')\n",
    "# -------------------------------------------------------\n",
    "\n",
    "\n",
    "class Timer:\n",
    "    import time\n",
    "\n",
    "    def __init__(self):\n",
    "        self.t1 = self.t2 = 0\n",
    "        self.dt = 0\n",
    "\n",
    "    def start(self):\n",
    "        self.t1 = self.time.perf_counter()\n",
    "\n",
    "    def stop(self):\n",
    "        self.t2 = self.time.perf_counter()\n",
    "        self.dt += self.t2 - self.t1\n",
    "\n",
    "    def reset(self):\n",
    "        self.__init__()\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.dt:.3f} s'\n",
    "\n",
    "\n",
    "def process_chunk(proc_id, n_procs, total_rows, chunk_size, infile, outfile):\n",
    "    # удалить старые выходные файлы каждого процесса, если таковые имеются\n",
    "    # result_0.csv, result_1.csv, и т.д.\n",
    "    remove_file(outfile.split('.csv')[0] + '_' + str(proc_id) + '.csv', no_warn=True)\n",
    "\n",
    "    # кол-во строк на обработку proc_id-м процессом\n",
    "    n_rows_per_process = total_rows // n_procs\n",
    "\n",
    "    # с какой строки обрабатывать\n",
    "    start_row = n_rows_per_process * proc_id\n",
    "\n",
    "    if proc_id == n_procs - 1:\n",
    "        n_rows_per_process += total_rows % n_procs\n",
    "\n",
    "    if proc_id != 0:\n",
    "        start_row += 1\n",
    "\n",
    "    if verbose:\n",
    "        print('process ', proc_id, ': processing ', n_rows_per_process,\n",
    "              ' rows [', start_row + int(proc_id == 0), ',', start_row + n_rows_per_process - int(proc_id != 0), ']', sep='')\n",
    "\n",
    "    chunker = pd.read_csv(\n",
    "        infile,\n",
    "        skiprows=range(1, start_row),\n",
    "        nrows=n_rows_per_process,\n",
    "        chunksize=chunk_size,\n",
    "    )\n",
    "\n",
    "    proc_outfile = outfile.split('.csv')[0] + '_' + str(proc_id) + '.csv'\n",
    "\n",
    "    if verbose:\n",
    "        processed = 0\n",
    "\n",
    "    # 0-й процесс пишет в result.csv новый header\n",
    "    if proc_id == 0:\n",
    "        hdr = pd.read_csv(infile, nrows=0)\n",
    "        del hdr['params.name']\n",
    "        del hdr['params.value']\n",
    "        for field in columns_2:\n",
    "            hdr[field] = []\n",
    "        hdr.to_csv(outfile, index=None)\n",
    "\n",
    "    for chunk in chunker:\n",
    "        chunk = chunk.loc[chunk.idAppVersionTitle.str.contains(version)]\n",
    "\n",
    "        columns_1 = list(chunk.columns)\n",
    "        columns_1.remove('params.name')\n",
    "        columns_1.remove('params.value')\n",
    "\n",
    "        df = pd.DataFrame(chunk[columns_1], columns=columns_1)\n",
    "\n",
    "        to_insert = {k: [] for k in columns_2}\n",
    "\n",
    "        for ind, row in chunk.iterrows():\n",
    "            # ---------------------------------------\n",
    "            if verbose:\n",
    "                TIME['to_list'].start()\n",
    "\n",
    "            names = str_to_list(row['params.name'])\n",
    "            values = str_to_list(row['params.value'])\n",
    "\n",
    "            if verbose:\n",
    "                TIME['to_list'].stop()\n",
    "            # ---------------------------------------\n",
    "\n",
    "            # -----------------------------------------\n",
    "            if verbose:\n",
    "                TIME['dict'].start()\n",
    "\n",
    "            names_ind = {}\n",
    "            for k, v in enumerate(names):\n",
    "                names_ind[v] = k\n",
    "\n",
    "            indices = [names_ind[k] for k in columns_2]\n",
    "\n",
    "            if verbose:\n",
    "                TIME['dict'].stop()\n",
    "            # -----------------------------------------\n",
    "\n",
    "            for t in columns_2:\n",
    "                if t in names_ind:\n",
    "                    i = names_ind[t]\n",
    "                    to_insert[t].append(values[i])\n",
    "\n",
    "        # -------------------------\n",
    "        if verbose:\n",
    "            TIME['merge'].start()\n",
    "\n",
    "        for _ in columns_2:\n",
    "            df[_] = to_insert[_]\n",
    "\n",
    "        if verbose:\n",
    "            TIME['merge'].stop()\n",
    "        # -------------------------\n",
    "\n",
    "        if verbose:\n",
    "            processed += len(df.index)\n",
    "            print('process ', proc_id, ': ', processed, ' rows processed', sep='')\n",
    "\n",
    "        df.to_csv(proc_outfile, mode='a', header=False, index=False)\n",
    "\n",
    "    if verbose:\n",
    "        print('process ', proc_id, ': FINISHED', sep='', end='\\t[')\n",
    "        print('TIME:', end=' ')\n",
    "        for k, v in TIME.items():\n",
    "            print(k, '-', v, end=', ')\n",
    "        print('\\b\\b]')\n",
    "\n",
    "\n",
    "# --------------------------------------------------------------------------------------------------------\n",
    "remove_file(outfile, no_warn=True)\n",
    "\n",
    "TIME = {}\n",
    "for field in ['to_list', 'dict', 'merge']:\n",
    "    TIME[field] = Timer()\n",
    "\n",
    "processes = []  # массив процессов\n",
    "\n",
    "for proc_id in range(n_procs):\n",
    "    p = mp.Process(target=process_chunk, args=(proc_id, n_procs, total_rows, chunk_size, infile, outfile))\n",
    "    processes.append(p)\n",
    "\n",
    "# запускаем процессы в обратном порядке,\n",
    "# т.к. последним потребуется скипать строки при чтении csv\n",
    "for p in processes[::-1]:\n",
    "    p.start()\n",
    "\n",
    "for proc_id in range(len(processes)):\n",
    "    # дожидаемся очередного процесса\n",
    "    processes[proc_id].join()\n",
    "\n",
    "    # дописываем его выходной файл в конец итогового файла result.csv (мерджим)\n",
    "    os.system('cat ' + outfile.split('.csv')[0] + '_' + str(proc_id) + '.csv >> ' + outfile)\n",
    "\n",
    "    if autoclean:\n",
    "        remove_file(outfile.split('.csv')[0] + '_' + str(proc_id) + '.csv')\n",
    "\n",
    "print('Finished !')\n",
    "# --------------------------------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
